{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "1a4572a7-337d-4da8-933e-77d85ab02a73",
            "metadata": {},
            "source": "<p style=\"text-align:center\">\n    <a href=\"https://skills.network/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDS0321ENSkillsNetwork865-2023-01-01\">\n    <img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/assets/logos/SN_web_lightmode.png\" width=\"200\" alt=\"Skills Network Logo\"  />\n    </a>\n</p>\n\n<h1 align=center><font size = 5>Assignment: SQL Notebook for Peer Assignment</font></h1>\n\nEstimated time needed: **60** minutes.\n\n## Introduction\nUsing this Python notebook you will:\n\n1.  Understand the Spacex DataSet\n2.  Load the dataset  into the corresponding table in a Db2 database\n3.  Execute SQL queries to answer assignment questions \n"
        },
        {
            "cell_type": "markdown",
            "id": "f0f042ef-27c0-4a64-94f5-b5f6ff99fa29",
            "metadata": {},
            "source": "## Overview of the DataSet\n\nSpaceX has gained worldwide attention for a series of historic milestones. \n\nIt is the only private company ever to return a spacecraft from low-earth orbit, which it first accomplished in December 2010.\nSpaceX advertises Falcon 9 rocket launches on its website with a cost of 62 million dollars wheras other providers cost upward of 165 million dollars each, much of the savings is because Space X can reuse the first stage. \n\n\nTherefore if we can determine if the first stage will land, we can determine the cost of a launch. \n\nThis information can be used if an alternate company wants to bid against SpaceX for a rocket launch.\n\nThis dataset includes a record for each payload carried during a SpaceX mission into outer space.\n"
        },
        {
            "cell_type": "markdown",
            "id": "9df33158-7234-4d15-83f0-acab745b6b06",
            "metadata": {},
            "source": "### Download the datasets\n\nThis assignment requires you to load the spacex dataset.\n\nIn many cases the dataset to be analyzed is available as a .CSV (comma separated values) file, perhaps on the internet. Click on the link below to download and save the dataset (.CSV file):\n\n <a href=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-DS0321EN-SkillsNetwork/labs/module_2/data/Spacex.csv\" target=\"_blank\">Spacex DataSet</a>\n\n"
        },
        {
            "cell_type": "markdown",
            "id": "7e594554-fe5c-4346-a1f3-38fb3e5c6126",
            "metadata": {},
            "source": "**Navigate to the Go to UI screen** \n\n* Refer to this insruction in this <a href=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-DB0201EN-SkillsNetwork/labs/Labs_Coursera_V5/labs/Lab%20-%20Sign%20up%20for%20IBM%20Cloud%20-%20Create%20Db2%20service%20instance%20-%20Get%20started%20with%20the%20Db2%20console/instructional-labs.md.html\">link</a> for viewing  the   Go to UI screen. \n\n\n* Later click on **Data link(below SQL)**  in the Go to UI screen  and click on **Load Data** tab.  \n\n\n\n* Later browse for the downloaded spacex file.\n\n\n\n<img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-DS0321EN-SkillsNetwork/labs/module_2/images/browsefile.png\" width=\"800\">\n\n\n* Once done select the schema andload the file.  \n\n\n <img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-DS0321EN-SkillsNetwork/labs/module_2/images/spacexload3.png\" width=\"800\">\n \n"
        },
        {
            "cell_type": "markdown",
            "id": "10e0e2ed-3414-4c28-ad6e-7e21c1863683",
            "metadata": {},
            "source": "\nIf you are facing a problem in uploading the dataset (which is a csv file), you can follow the steps below to upload the .sql file instead of the CSV file:\n\n* Download the file <a href=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-DS0321EN-SkillsNetwork/datasets/Spacex%20.sql\">Spacex.sql</a>\n\n* Later click on **SQL** in the  **Go to UI Screen**.\n\n* Use the **From file** option to browse for the **SQL** file and upload it.\n\n<img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-DS0321EN-SkillsNetwork/labs/module_2/images/sqlfile.png\">\n\n* Once you upload the script,you can use the **Run All** option to run all the queries to insert the data.\n\n<img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-DS0321EN-SkillsNetwork/labs/module_2/images/runall.png\">\n\n    \n"
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "id": "cfa51ac3-773f-464f-8613-0f40371d1237",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Collecting ibm_db==3.1.0\n  Downloading ibm_db-3.1.0.tar.gz (797 kB)\n\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m797.3/797.3 kB\u001b[0m \u001b[31m44.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n\u001b[?25h  Installing backend dependencies ... \u001b[?25ldone\n\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25hCollecting ibm_db_sa==0.3.3\n  Downloading ibm_db_sa-0.3.3.tar.gz (24 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hCollecting sqlalchemy>=0.7.3\n  Downloading SQLAlchemy-2.0.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.7 MB)\n\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m75.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hCollecting typing-extensions>=4.2.0\n  Downloading typing_extensions-4.5.0-py3-none-any.whl (27 kB)\nCollecting greenlet!=0.4.17\n  Downloading greenlet-2.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (613 kB)\n\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m613.7/613.7 kB\u001b[0m \u001b[31m65.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hBuilding wheels for collected packages: ibm_db, ibm_db_sa\n  Building wheel for ibm_db (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for ibm_db: filename=ibm_db-3.1.0-cp310-cp310-linux_x86_64.whl size=267276 sha256=b8ce17372accc5defc0f0bbd0d672c0a202821bbf40028f7b2c4e4c72ece8ffe\n  Stored in directory: /tmp/wsuser/.cache/pip/wheels/50/d7/3d/cf01ca490baa2f299aca0c791a2a5708d9b9676608374e2f31\n  Building wheel for ibm_db_sa (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for ibm_db_sa: filename=ibm_db_sa-0.3.3-py3-none-any.whl size=27425 sha256=a60f32a9f8871fef7ac25bf391a896da588f37308390ae36eea61c9c575b69f4\n  Stored in directory: /tmp/wsuser/.cache/pip/wheels/63/28/d7/aea2c85d7ff99e1e8dffc7424367812bf53659141c203f2c9a\nSuccessfully built ibm_db ibm_db_sa\nInstalling collected packages: ibm_db, typing-extensions, greenlet, sqlalchemy, ibm_db_sa\n  Attempting uninstall: ibm_db\n    Found existing installation: ibm-db 3.1.3\n    Uninstalling ibm-db-3.1.3:\n      Successfully uninstalled ibm-db-3.1.3\n  Attempting uninstall: typing-extensions\n    Found existing installation: typing_extensions 4.3.0\n    Uninstalling typing_extensions-4.3.0:\n      Successfully uninstalled typing_extensions-4.3.0\n  Attempting uninstall: greenlet\n    Found existing installation: greenlet 1.1.1\n    Uninstalling greenlet-1.1.1:\n      Successfully uninstalled greenlet-1.1.1\n  Attempting uninstall: sqlalchemy\n    Found existing installation: SQLAlchemy 1.4.39\n    Uninstalling SQLAlchemy-1.4.39:\n      Successfully uninstalled SQLAlchemy-1.4.39\n  Attempting uninstall: ibm_db_sa\n    Found existing installation: ibm-db-sa 0.3.8\n    Uninstalling ibm-db-sa-0.3.8:\n      Successfully uninstalled ibm-db-sa-0.3.8\nSuccessfully installed greenlet-2.0.2 ibm_db-3.1.0 ibm_db_sa-0.3.3 sqlalchemy-2.0.8 typing-extensions-4.5.0\nCollecting sqlalchemy==1.3.24\n  Downloading SQLAlchemy-1.3.24.tar.gz (6.4 MB)\n\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m6.4/6.4 MB\u001b[0m \u001b[31m75.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hBuilding wheels for collected packages: sqlalchemy\n  Building wheel for sqlalchemy (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for sqlalchemy: filename=SQLAlchemy-1.3.24-cp310-cp310-linux_x86_64.whl size=1219926 sha256=df56089d738732358e24d72907d6ec97e881311b712337c6469c5c9d8d2d1a4e\n  Stored in directory: /tmp/wsuser/.cache/pip/wheels/27/51/b3/3481e88d5a5ba95dd4aafedc9316774d941c4ba61cfb93add8\nSuccessfully built sqlalchemy\nInstalling collected packages: sqlalchemy\n  Attempting uninstall: sqlalchemy\n    Found existing installation: SQLAlchemy 2.0.8\n    Uninstalling SQLAlchemy-2.0.8:\n      Successfully uninstalled SQLAlchemy-2.0.8\nSuccessfully installed sqlalchemy-1.3.24\n\u001b[33mWARNING: Skipping ipython-sql as it is not installed.\u001b[0m\u001b[33m\n\u001b[0mCollecting ipython-sql==0.4.1\n  Downloading ipython_sql-0.4.1-py3-none-any.whl (21 kB)\nRequirement already satisfied: ipython-genutils>=0.1.0 in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from ipython-sql==0.4.1) (0.2.0)\nRequirement already satisfied: six in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from ipython-sql==0.4.1) (1.16.0)\nRequirement already satisfied: sqlalchemy>=0.6.7 in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from ipython-sql==0.4.1) (1.3.24)\nCollecting sqlparse\n  Downloading sqlparse-0.4.3-py3-none-any.whl (42 kB)\n\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m42.8/42.8 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: ipython>=1.0 in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from ipython-sql==0.4.1) (8.4.0)\nCollecting prettytable<1\n  Downloading prettytable-0.7.2.zip (28 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: traitlets>=5 in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from ipython>=1.0->ipython-sql==0.4.1) (5.1.1)\nRequirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from ipython>=1.0->ipython-sql==0.4.1) (3.0.20)\nRequirement already satisfied: pygments>=2.4.0 in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from ipython>=1.0->ipython-sql==0.4.1) (2.11.2)\nRequirement already satisfied: pexpect>4.3 in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from ipython>=1.0->ipython-sql==0.4.1) (4.8.0)\nRequirement already satisfied: stack-data in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from ipython>=1.0->ipython-sql==0.4.1) (0.2.0)\nRequirement already satisfied: backcall in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from ipython>=1.0->ipython-sql==0.4.1) (0.2.0)\nRequirement already satisfied: matplotlib-inline in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from ipython>=1.0->ipython-sql==0.4.1) (0.1.6)\nRequirement already satisfied: setuptools>=18.5 in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from ipython>=1.0->ipython-sql==0.4.1) (65.6.3)\nRequirement already satisfied: pickleshare in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from ipython>=1.0->ipython-sql==0.4.1) (0.7.5)\nRequirement already satisfied: jedi>=0.16 in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from ipython>=1.0->ipython-sql==0.4.1) (0.18.1)\nRequirement already satisfied: decorator in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from ipython>=1.0->ipython-sql==0.4.1) (5.1.1)\nRequirement already satisfied: parso<0.9.0,>=0.8.0 in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from jedi>=0.16->ipython>=1.0->ipython-sql==0.4.1) (0.8.3)\nRequirement already satisfied: ptyprocess>=0.5 in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from pexpect>4.3->ipython>=1.0->ipython-sql==0.4.1) (0.7.0)\nRequirement already satisfied: wcwidth in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=1.0->ipython-sql==0.4.1) (0.2.5)\nRequirement already satisfied: executing in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from stack-data->ipython>=1.0->ipython-sql==0.4.1) (0.8.3)\nRequirement already satisfied: pure-eval in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from stack-data->ipython>=1.0->ipython-sql==0.4.1) (0.2.2)\nRequirement already satisfied: asttokens in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from stack-data->ipython>=1.0->ipython-sql==0.4.1) (2.0.5)\nBuilding wheels for collected packages: prettytable\n  Building wheel for prettytable (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for prettytable: filename=prettytable-0.7.2-py3-none-any.whl size=13713 sha256=e10cc8002ade8c23d54b5c6f01fd4a666ef6ec33a9005edb010729af21490a73\n  Stored in directory: /tmp/wsuser/.cache/pip/wheels/25/4b/07/18c5d92824315576e478206ea69df34a9e31958f6143eb0e31\nSuccessfully built prettytable\nInstalling collected packages: prettytable, sqlparse, ipython-sql\nSuccessfully installed ipython-sql-0.4.1 prettytable-0.7.2 sqlparse-0.4.3\n"
                }
            ],
            "source": "!pip install --force-reinstall ibm_db==3.1.0 ibm_db_sa==0.3.3\n!pip install sqlalchemy==1.3.24\n!pip uninstall ipython-sql -y\n!pip install ipython-sql==0.4.1"
        },
        {
            "cell_type": "markdown",
            "id": "c3dba6f4-b072-426f-a321-170cc50d9d54",
            "metadata": {},
            "source": "### Connect to the database\n\nLet us first load the SQL extension and establish a connection with the database\n"
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "id": "f6d1a362-0ff3-489a-89bf-89e07ae36de6",
            "metadata": {},
            "outputs": [],
            "source": "%load_ext sql"
        },
        {
            "cell_type": "markdown",
            "id": "0d0f926b-bc7f-4fa8-bfb7-1df4c6eef9b1",
            "metadata": {},
            "source": "\n\n\n**DB2 magic in case of  UI service credentials.**\n\n\n\n<img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-DS0321EN-SkillsNetwork/labs/module_2/images/servicecredentials.png\" width=\"600\">  \n\n* Use the following format.\n\n* Add security=SSL at the end\n\n**%sql ibm_db_sa://my-username:my-password@my-hostname:my-port/my-db-name?security=SSL**\n"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "c440ae0e-a4d2-4775-8ce4-da4668ea088e",
            "metadata": {},
            "outputs": [],
            "source": ""
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "5e21609d-8105-46f0-b6a7-9aa6569b323b",
            "metadata": {},
            "outputs": [],
            "source": ""
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "id": "88bdd54b-9c54-4045-a2cc-36150de56071",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Connection info needed in SQLAlchemy format, example:\n               postgresql://username:password@hostname/dbname\n               or an existing connection: dict_keys([])\nCan't load plugin: sqlalchemy.dialects:ibm_db_sa\nConnection info needed in SQLAlchemy format, example:\n               postgresql://username:password@hostname/dbname\n               or an existing connection: dict_keys([])\n"
                }
            ],
            "source": "%sql ibm_db_sa://"
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [],
            "source": "import pandas as pd\ndf = pd.read_csv('https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-DS0321EN-SkillsNetwork/labs/module_2/data/Spacex.csv')"
        },
        {
            "cell_type": "markdown",
            "id": "b0eba71f-c487-4645-a9db-b38e3de859bd",
            "metadata": {},
            "source": "## Tasks\n\nNow write and execute SQL queries to solve the assignment tasks.\n\n### Task 1\n\n\n\n\n##### Display the names of the unique launch sites  in the space mission\n"
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": "array(['CCAFS LC-40', 'VAFB SLC-4E', 'KSC LC-39A', 'CCAFS SLC-40'],\n      dtype=object)"
                    },
                    "execution_count": 9,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "df['Launch_Site'].unique()"
        },
        {
            "cell_type": "markdown",
            "id": "3dcd6095-ce1e-47fe-b980-82ec5c94868b",
            "metadata": {},
            "source": "\n### Task 2\n\n\n#####  Display 5 records where launch sites begin with the string 'CCA' \n"
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "id": "546fb108-e3e5-4cd0-85c4-59d7b1c3de4e",
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Date</th>\n      <th>Time (UTC)</th>\n      <th>Booster_Version</th>\n      <th>Launch_Site</th>\n      <th>Payload</th>\n      <th>PAYLOAD_MASS__KG_</th>\n      <th>Orbit</th>\n      <th>Customer</th>\n      <th>Mission_Outcome</th>\n      <th>Landing _Outcome</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>04-06-2010</td>\n      <td>18:45:00</td>\n      <td>F9 v1.0  B0003</td>\n      <td>CCAFS LC-40</td>\n      <td>Dragon Spacecraft Qualification Unit</td>\n      <td>0</td>\n      <td>LEO</td>\n      <td>SpaceX</td>\n      <td>Success</td>\n      <td>Failure (parachute)</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>08-12-2010</td>\n      <td>15:43:00</td>\n      <td>F9 v1.0  B0004</td>\n      <td>CCAFS LC-40</td>\n      <td>Dragon demo flight C1, two CubeSats, barrel of...</td>\n      <td>0</td>\n      <td>LEO (ISS)</td>\n      <td>NASA (COTS) NRO</td>\n      <td>Success</td>\n      <td>Failure (parachute)</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>22-05-2012</td>\n      <td>07:44:00</td>\n      <td>F9 v1.0  B0005</td>\n      <td>CCAFS LC-40</td>\n      <td>Dragon demo flight C2</td>\n      <td>525</td>\n      <td>LEO (ISS)</td>\n      <td>NASA (COTS)</td>\n      <td>Success</td>\n      <td>No attempt</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>08-10-2012</td>\n      <td>00:35:00</td>\n      <td>F9 v1.0  B0006</td>\n      <td>CCAFS LC-40</td>\n      <td>SpaceX CRS-1</td>\n      <td>500</td>\n      <td>LEO (ISS)</td>\n      <td>NASA (CRS)</td>\n      <td>Success</td>\n      <td>No attempt</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>01-03-2013</td>\n      <td>15:10:00</td>\n      <td>F9 v1.0  B0007</td>\n      <td>CCAFS LC-40</td>\n      <td>SpaceX CRS-2</td>\n      <td>677</td>\n      <td>LEO (ISS)</td>\n      <td>NASA (CRS)</td>\n      <td>Success</td>\n      <td>No attempt</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
                        "text/plain": "         Date Time (UTC) Booster_Version  Launch_Site  \\\n0  04-06-2010   18:45:00  F9 v1.0  B0003  CCAFS LC-40   \n1  08-12-2010   15:43:00  F9 v1.0  B0004  CCAFS LC-40   \n2  22-05-2012   07:44:00  F9 v1.0  B0005  CCAFS LC-40   \n3  08-10-2012   00:35:00  F9 v1.0  B0006  CCAFS LC-40   \n4  01-03-2013   15:10:00  F9 v1.0  B0007  CCAFS LC-40   \n\n                                             Payload  PAYLOAD_MASS__KG_  \\\n0               Dragon Spacecraft Qualification Unit                  0   \n1  Dragon demo flight C1, two CubeSats, barrel of...                  0   \n2                              Dragon demo flight C2                525   \n3                                       SpaceX CRS-1                500   \n4                                       SpaceX CRS-2                677   \n\n       Orbit         Customer Mission_Outcome     Landing _Outcome  \n0        LEO           SpaceX         Success  Failure (parachute)  \n1  LEO (ISS)  NASA (COTS) NRO         Success  Failure (parachute)  \n2  LEO (ISS)      NASA (COTS)         Success           No attempt  \n3  LEO (ISS)       NASA (CRS)         Success           No attempt  \n4  LEO (ISS)       NASA (CRS)         Success           No attempt  "
                    },
                    "execution_count": 12,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "df[df['Launch_Site'].str.startswith('CCA')].head()"
        },
        {
            "cell_type": "markdown",
            "id": "c71c6965-cf7d-4d67-ac53-a02bfd9989d1",
            "metadata": {},
            "source": "### Task 3\n\n\n\n\n##### Display the total payload mass carried by boosters launched by NASA (CRS)\n"
        },
        {
            "cell_type": "code",
            "execution_count": 14,
            "id": "880f11e0-4aa3-46cd-a6c6-7b5f483544f0",
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": "45596"
                    },
                    "execution_count": 14,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "df[df['Customer'] == 'NASA (CRS)']['PAYLOAD_MASS__KG_'].sum()"
        },
        {
            "cell_type": "markdown",
            "id": "390dab14-7504-49dd-80d1-845142f118e9",
            "metadata": {},
            "source": "### Task 4\n\n\n\n\n##### Display average payload mass carried by booster version F9 v1.1\n"
        },
        {
            "cell_type": "code",
            "execution_count": 17,
            "id": "f5556b76-1f7b-4cdf-9802-0ae766b032ff",
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": "2534.6666666666665"
                    },
                    "execution_count": 17,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "df[df['Booster_Version'].str.startswith('F9 v1.1')]['PAYLOAD_MASS__KG_'].mean()"
        },
        {
            "cell_type": "markdown",
            "id": "2e1a7ec4-bbd5-403b-9e8d-2772313b32a7",
            "metadata": {},
            "source": "### Task 5\n\n##### List the date when the first successful landing outcome in ground pad was acheived.\n\n\n_Hint:Use min function_ \n"
        },
        {
            "cell_type": "code",
            "execution_count": 21,
            "id": "1cc1dbe7-cb50-4b40-8db3-b4d4cdee01a5",
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": "'01-05-2017'"
                    },
                    "execution_count": 21,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "df[df['Landing _Outcome'] == 'Success (ground pad)']['Date'].min()"
        },
        {
            "cell_type": "markdown",
            "id": "61b1d91a-b208-4beb-80d4-00624dbe46a8",
            "metadata": {},
            "source": "### Task 6\n\n##### List the names of the boosters which have success in drone ship and have payload mass greater than 4000 but less than 6000\n"
        },
        {
            "cell_type": "code",
            "execution_count": 26,
            "id": "521f4752-62e6-402b-ac53-42b8795dc1c4",
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": "28    F9 FT B1029.1\n36    F9 FT B1036.1\n41    F9 B4 B1041.1\nName: Booster_Version, dtype: object"
                    },
                    "execution_count": 26,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "df[(df['Landing _Outcome'] == 'Success (drone ship)') & (df['PAYLOAD_MASS__KG_'] > 4000) & (df['PAYLOAD_MASS__KG_'] > 6000)]['Booster_Version']"
        },
        {
            "cell_type": "markdown",
            "id": "ceccf431-8329-4443-875f-1505a5c2c083",
            "metadata": {},
            "source": "### Task 7\n\n\n\n\n##### List the total number of successful and failure mission outcomes\n"
        },
        {
            "cell_type": "code",
            "execution_count": 31,
            "id": "f0099236-66c8-4369-ae2d-fc5aae522610",
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": "61"
                    },
                    "execution_count": 31,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "(df['Landing _Outcome'].str.contains('Success')).sum()"
        },
        {
            "cell_type": "markdown",
            "id": "cffcca0b-2fb7-45a9-afd6-a2af9edcddfa",
            "metadata": {},
            "source": "### Task 8\n\n\n\n##### List the   names of the booster_versions which have carried the maximum payload mass. Use a subquery\n"
        },
        {
            "cell_type": "code",
            "execution_count": 33,
            "id": "2cb7b593-2192-47e4-99c5-2bc62ca6ebd5",
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": "74     F9 B5 B1048.4\n77     F9 B5 B1049.4\n79     F9 B5 B1051.3\n80     F9 B5 B1056.4\n82     F9 B5 B1048.5\n83     F9 B5 B1051.4\n85     F9 B5 B1049.5\n92    F9 B5 B1060.2 \n93    F9 B5 B1058.3 \n94     F9 B5 B1051.6\n95     F9 B5 B1060.3\n99    F9 B5 B1049.7 \nName: Booster_Version, dtype: object"
                    },
                    "execution_count": 33,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "df[df['PAYLOAD_MASS__KG_'] == df['PAYLOAD_MASS__KG_'].max()]['Booster_Version']"
        },
        {
            "cell_type": "markdown",
            "id": "d81d8af0-6542-4c3b-8713-d2c266a36434",
            "metadata": {},
            "source": "### Task 9\n\n\n##### List the failed landing_outcomes in drone ship, their booster versions, and launch site names for in year 2015\n"
        },
        {
            "cell_type": "code",
            "execution_count": 52,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Date</th>\n      <th>Booster_Version</th>\n      <th>Launch_Site</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>13</th>\n      <td>10-01-2015</td>\n      <td>F9 v1.1 B1012</td>\n      <td>CCAFS LC-40</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>14-04-2015</td>\n      <td>F9 v1.1 B1015</td>\n      <td>CCAFS LC-40</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
                        "text/plain": "          Date Booster_Version  Launch_Site\n13  10-01-2015   F9 v1.1 B1012  CCAFS LC-40\n16  14-04-2015   F9 v1.1 B1015  CCAFS LC-40"
                    },
                    "execution_count": 52,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "df[(df['Landing _Outcome'] == 'Failure (drone ship)') & (df['Date'].str.split('-').apply(lambda x: x[2]).astype(int) == 2015)][['Date','Booster_Version', 'Launch_Site']]"
        },
        {
            "cell_type": "markdown",
            "id": "cbfc7853-46d8-4a89-9468-1170274ec555",
            "metadata": {},
            "source": "### Task 10\n\n##### Rank the count of landing outcomes (such as Failure (drone ship) or Success (ground pad)) between the date 2010-06-04 and 2017-03-20, in descending order\n"
        },
        {
            "cell_type": "code",
            "execution_count": 61,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": "array(['CCAFS LC-40', 'VAFB SLC-4E', 'KSC LC-39A', 'CCAFS SLC-40'],\n      dtype=object)"
                    },
                    "execution_count": 61,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "df['Launch_Site'].unique()"
        },
        {
            "cell_type": "code",
            "execution_count": 59,
            "id": "a1aecee7-7189-4189-9c74-c0808ac34cd6",
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": "/tmp/wsuser/ipykernel_522/60918191.py:1: UserWarning: Parsing '22-05-2012' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n  df['Date_'] = pd.to_datetime(df['Date'])\n/tmp/wsuser/ipykernel_522/60918191.py:1: UserWarning: Parsing '29-09-2013' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n  df['Date_'] = pd.to_datetime(df['Date'])\n/tmp/wsuser/ipykernel_522/60918191.py:1: UserWarning: Parsing '18-04-2014' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n  df['Date_'] = pd.to_datetime(df['Date'])\n/tmp/wsuser/ipykernel_522/60918191.py:1: UserWarning: Parsing '14-07-2014' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n  df['Date_'] = pd.to_datetime(df['Date'])\n/tmp/wsuser/ipykernel_522/60918191.py:1: UserWarning: Parsing '21-09-2014' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n  df['Date_'] = pd.to_datetime(df['Date'])\n/tmp/wsuser/ipykernel_522/60918191.py:1: UserWarning: Parsing '14-04-2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n  df['Date_'] = pd.to_datetime(df['Date'])\n/tmp/wsuser/ipykernel_522/60918191.py:1: UserWarning: Parsing '27-04-2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n  df['Date_'] = pd.to_datetime(df['Date'])\n/tmp/wsuser/ipykernel_522/60918191.py:1: UserWarning: Parsing '28-06-2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n  df['Date_'] = pd.to_datetime(df['Date'])\n/tmp/wsuser/ipykernel_522/60918191.py:1: UserWarning: Parsing '22-12-2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n  df['Date_'] = pd.to_datetime(df['Date'])\n/tmp/wsuser/ipykernel_522/60918191.py:1: UserWarning: Parsing '17-01-2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n  df['Date_'] = pd.to_datetime(df['Date'])\n/tmp/wsuser/ipykernel_522/60918191.py:1: UserWarning: Parsing '27-05-2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n  df['Date_'] = pd.to_datetime(df['Date'])\n/tmp/wsuser/ipykernel_522/60918191.py:1: UserWarning: Parsing '15-06-2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n  df['Date_'] = pd.to_datetime(df['Date'])\n/tmp/wsuser/ipykernel_522/60918191.py:1: UserWarning: Parsing '18-07-2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n  df['Date_'] = pd.to_datetime(df['Date'])\n/tmp/wsuser/ipykernel_522/60918191.py:1: UserWarning: Parsing '14-08-2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n  df['Date_'] = pd.to_datetime(df['Date'])\n/tmp/wsuser/ipykernel_522/60918191.py:1: UserWarning: Parsing '14-01-2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n  df['Date_'] = pd.to_datetime(df['Date'])\n/tmp/wsuser/ipykernel_522/60918191.py:1: UserWarning: Parsing '19-02-2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n  df['Date_'] = pd.to_datetime(df['Date'])\n/tmp/wsuser/ipykernel_522/60918191.py:1: UserWarning: Parsing '16-03-2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n  df['Date_'] = pd.to_datetime(df['Date'])\n/tmp/wsuser/ipykernel_522/60918191.py:1: UserWarning: Parsing '30-03-2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n  df['Date_'] = pd.to_datetime(df['Date'])\n/tmp/wsuser/ipykernel_522/60918191.py:1: UserWarning: Parsing '15-05-2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n  df['Date_'] = pd.to_datetime(df['Date'])\n/tmp/wsuser/ipykernel_522/60918191.py:1: UserWarning: Parsing '23-06-2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n  df['Date_'] = pd.to_datetime(df['Date'])\n/tmp/wsuser/ipykernel_522/60918191.py:1: UserWarning: Parsing '25-06-2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n  df['Date_'] = pd.to_datetime(df['Date'])\n/tmp/wsuser/ipykernel_522/60918191.py:1: UserWarning: Parsing '14-08-2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n  df['Date_'] = pd.to_datetime(df['Date'])\n/tmp/wsuser/ipykernel_522/60918191.py:1: UserWarning: Parsing '24-08-2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n  df['Date_'] = pd.to_datetime(df['Date'])\n/tmp/wsuser/ipykernel_522/60918191.py:1: UserWarning: Parsing '30-10-2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n  df['Date_'] = pd.to_datetime(df['Date'])\n/tmp/wsuser/ipykernel_522/60918191.py:1: UserWarning: Parsing '15-12-2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n  df['Date_'] = pd.to_datetime(df['Date'])\n/tmp/wsuser/ipykernel_522/60918191.py:1: UserWarning: Parsing '23-12-2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n  df['Date_'] = pd.to_datetime(df['Date'])\n/tmp/wsuser/ipykernel_522/60918191.py:1: UserWarning: Parsing '31-01-2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n  df['Date_'] = pd.to_datetime(df['Date'])\n/tmp/wsuser/ipykernel_522/60918191.py:1: UserWarning: Parsing '22-02-2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n  df['Date_'] = pd.to_datetime(df['Date'])\n/tmp/wsuser/ipykernel_522/60918191.py:1: UserWarning: Parsing '30-03-2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n  df['Date_'] = pd.to_datetime(df['Date'])\n/tmp/wsuser/ipykernel_522/60918191.py:1: UserWarning: Parsing '18-04-2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n  df['Date_'] = pd.to_datetime(df['Date'])\n/tmp/wsuser/ipykernel_522/60918191.py:1: UserWarning: Parsing '22-05-2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n  df['Date_'] = pd.to_datetime(df['Date'])\n/tmp/wsuser/ipykernel_522/60918191.py:1: UserWarning: Parsing '29-06-2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n  df['Date_'] = pd.to_datetime(df['Date'])\n/tmp/wsuser/ipykernel_522/60918191.py:1: UserWarning: Parsing '22-07-2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n  df['Date_'] = pd.to_datetime(df['Date'])\n/tmp/wsuser/ipykernel_522/60918191.py:1: UserWarning: Parsing '25-07-2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n  df['Date_'] = pd.to_datetime(df['Date'])\n/tmp/wsuser/ipykernel_522/60918191.py:1: UserWarning: Parsing '15-11-2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n  df['Date_'] = pd.to_datetime(df['Date'])\n/tmp/wsuser/ipykernel_522/60918191.py:1: UserWarning: Parsing '23-12-2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n  df['Date_'] = pd.to_datetime(df['Date'])\n/tmp/wsuser/ipykernel_522/60918191.py:1: UserWarning: Parsing '22-02-2019' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n  df['Date_'] = pd.to_datetime(df['Date'])\n/tmp/wsuser/ipykernel_522/60918191.py:1: UserWarning: Parsing '24-05-2019' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n  df['Date_'] = pd.to_datetime(df['Date'])\n/tmp/wsuser/ipykernel_522/60918191.py:1: UserWarning: Parsing '25-07-2019' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n  df['Date_'] = pd.to_datetime(df['Date'])\n/tmp/wsuser/ipykernel_522/60918191.py:1: UserWarning: Parsing '17-12-2019' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n  df['Date_'] = pd.to_datetime(df['Date'])\n/tmp/wsuser/ipykernel_522/60918191.py:1: UserWarning: Parsing '19-01-2020' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n  df['Date_'] = pd.to_datetime(df['Date'])\n/tmp/wsuser/ipykernel_522/60918191.py:1: UserWarning: Parsing '29-01-2020' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n  df['Date_'] = pd.to_datetime(df['Date'])\n/tmp/wsuser/ipykernel_522/60918191.py:1: UserWarning: Parsing '17-02-2020' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n  df['Date_'] = pd.to_datetime(df['Date'])\n/tmp/wsuser/ipykernel_522/60918191.py:1: UserWarning: Parsing '18-03-2020' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n  df['Date_'] = pd.to_datetime(df['Date'])\n/tmp/wsuser/ipykernel_522/60918191.py:1: UserWarning: Parsing '22-04-2020' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n  df['Date_'] = pd.to_datetime(df['Date'])\n/tmp/wsuser/ipykernel_522/60918191.py:1: UserWarning: Parsing '30-05-2020' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n  df['Date_'] = pd.to_datetime(df['Date'])\n/tmp/wsuser/ipykernel_522/60918191.py:1: UserWarning: Parsing '13-06-2020' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n  df['Date_'] = pd.to_datetime(df['Date'])\n/tmp/wsuser/ipykernel_522/60918191.py:1: UserWarning: Parsing '30-06-2020' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n  df['Date_'] = pd.to_datetime(df['Date'])\n/tmp/wsuser/ipykernel_522/60918191.py:1: UserWarning: Parsing '20-07-2020' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n  df['Date_'] = pd.to_datetime(df['Date'])\n/tmp/wsuser/ipykernel_522/60918191.py:1: UserWarning: Parsing '18-08-2020' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n  df['Date_'] = pd.to_datetime(df['Date'])\n/tmp/wsuser/ipykernel_522/60918191.py:1: UserWarning: Parsing '30-08-2020' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n  df['Date_'] = pd.to_datetime(df['Date'])\n/tmp/wsuser/ipykernel_522/60918191.py:1: UserWarning: Parsing '18-10-2020' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n  df['Date_'] = pd.to_datetime(df['Date'])\n/tmp/wsuser/ipykernel_522/60918191.py:1: UserWarning: Parsing '24-10-2020' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n  df['Date_'] = pd.to_datetime(df['Date'])\n/tmp/wsuser/ipykernel_522/60918191.py:1: UserWarning: Parsing '16-11-2020' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n  df['Date_'] = pd.to_datetime(df['Date'])\n/tmp/wsuser/ipykernel_522/60918191.py:1: UserWarning: Parsing '21-11-2020' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n  df['Date_'] = pd.to_datetime(df['Date'])\n/tmp/wsuser/ipykernel_522/60918191.py:1: UserWarning: Parsing '25-11-2020' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n  df['Date_'] = pd.to_datetime(df['Date'])\n"
                },
                {
                    "data": {
                        "text/plain": "No attempt                10\nFailure (drone ship)       5\nSuccess (ground pad)       5\nSuccess (drone ship)       5\nControlled (ocean)         3\nUncontrolled (ocean)       2\nFailure (parachute)        1\nPrecluded (drone ship)     1\nName: Landing _Outcome, dtype: int64"
                    },
                    "execution_count": 59,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "df['Date_'] = pd.to_datetime(df['Date'])\ndf['Landing _Outcome'][(df['Date_'] >= '2010-06-04') & (df['Date_'] <= '2017-03-20')].value_counts()"
        },
        {
            "cell_type": "markdown",
            "id": "07c75a47-4b2b-4dba-a09d-2890d61169ca",
            "metadata": {},
            "source": "### Reference Links\n\n* <a href =\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-DB0201EN-SkillsNetwork/labs/Labs_Coursera_V5/labs/Lab%20-%20String%20Patterns%20-%20Sorting%20-%20Grouping/instructional-labs.md.html?origin=www.coursera.org\">Hands-on Lab : String Patterns, Sorting and Grouping</a>  \n\n*  <a  href=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-DB0201EN-SkillsNetwork/labs/Labs_Coursera_V5/labs/Lab%20-%20Built-in%20functions%20/Hands-on_Lab__Built-in_Functions.md.html?origin=www.coursera.org\">Hands-on Lab: Built-in functions</a>\n\n*  <a  href=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-DB0201EN-SkillsNetwork/labs/Labs_Coursera_V5/labs/Lab%20-%20Sub-queries%20and%20Nested%20SELECTs%20/instructional-labs.md.html?origin=www.coursera.org\">Hands-on Lab : Sub-queries and Nested SELECT Statements</a>\n\n*   <a href=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-DB0201EN-SkillsNetwork/labs/Module%205/DB0201EN-Week3-1-3-SQLmagic.ipynb\">Hands-on Tutorial: Accessing Databases with SQL magic</a>\n\n*  <a href= \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-DB0201EN-SkillsNetwork/labs/Module%205/DB0201EN-Week3-1-4-Analyzing.ipynb\">Hands-on Lab: Analyzing a real World Data Set</a>\n\n\n"
        },
        {
            "cell_type": "markdown",
            "id": "76a8e6fb-7dfe-4e28-ab8e-c240920ae1d3",
            "metadata": {},
            "source": "## Author(s)\n\n<h4> Lakshmi Holla </h4>\n"
        },
        {
            "cell_type": "markdown",
            "id": "5b99ecdf-6aa7-4cca-b6fc-bbc01e78f553",
            "metadata": {},
            "source": "## Other Contributors\n\n<h4> Rav Ahuja </h4>\n"
        },
        {
            "cell_type": "markdown",
            "id": "b0f48c22-b195-4751-9638-48a6e6948a22",
            "metadata": {},
            "source": "## Change log\n| Date | Version | Changed by | Change Description |\n|------|--------|--------|---------|\n| 2021-10-12 | 0.4 |Lakshmi Holla | Changed markdown|\n| 2021-08-24 | 0.3 |Lakshmi Holla | Added library update|\n| 2021-07-09 | 0.2 |Lakshmi Holla | Changes made in magic sql|\n| 2021-05-20 | 0.1 |Lakshmi Holla | Created Initial Version |\n"
        },
        {
            "cell_type": "markdown",
            "id": "04d29bb5-339b-4842-b38c-af6de62d5ad5",
            "metadata": {},
            "source": "## <h3 align=\"center\"> \u00a9 IBM Corporation 2021. All rights reserved. <h3/>\n"
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.10",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.9"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}